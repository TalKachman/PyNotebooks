{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from gensim import corpora, models, similarities\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=qa\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load in text data from SQL </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    catagory text,\\\n",
    "    questionType text,\\\n",
    "    answerType text,\\\n",
    "    asin text,\\\n",
    "    answerTime TimeStamp,\\\n",
    "    unixTime int,\\\n",
    "    question text,\\\n",
    "    answer text\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def process_line(sentence):\n",
    "#    filter_text=' '.join(re.findall(\"[a-z'?]+\", sentence.lower()))\n",
    "#    #return nltk.word_tokenize(filter_text)\n",
    "#    return filter_text.replace('?',' ? ').split()\n",
    "\n",
    "def process_line(sentence):\n",
    "    #step 1 split if we need to\n",
    "    sentences=re.split(r'[;:!?.-]\\s*', sentence)\n",
    "    result= [re.findall(\"[a-z']+\", sent.lower()) for sent in sentences if \\\n",
    "           re.findall(\"[a-z']+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=['']\n",
    "    return result\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clean up sentence </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qs= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Qresults]\n",
    "#want to train model on all questions. Here we only return the first sentnece. To be labeled later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'well', 'does', 'this', 'work', 'podcasting']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clean up the sentences (for twitter) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Qsentence= [[word for word in sentence[0].lower().split() if word not in stoplist \\\n",
    "                  and re.findall('http',word)==[] and re.findall('@',word)==[]\\\n",
    "                 and re.findall('#',word)==[]] for sentence in Qrestuls]\n",
    "Asentence= [[word for word in sentence[0].lower().split() if word not in stoplist \\\n",
    "                  and re.findall('http',word)==[] and re.findall('@',word)==[]\\\n",
    "                 and re.findall('#',word)==[]] for sentence in Arestuls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Asentence[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Qmodel = models.Word2Vec(question_sentence, size=100, window=5, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('could', 0.9090049266815186),\n",
       " ('must', 0.6884556412696838),\n",
       " ('able', 0.6011472940444946),\n",
       " ('should', 0.5577580332756042),\n",
       " ('cant', 0.521159291267395),\n",
       " ('will', 0.5159804224967957),\n",
       " ('would', 0.5070073008537292),\n",
       " ('intend', 0.5025068521499634),\n",
       " ('may', 0.5004855394363403),\n",
       " (\"'d\", 0.4943317472934723)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qmodel.most_similar('can')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YN_flags=['can I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train for Bigrams </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Qbigram = models.Phrases(qs,min_count=2)\n",
    "Qbigrams=list(Qbigram[qs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'replacement', u'part', u'delicate', u'piece', u'on', u'zoom_h'],\n",
       " [u'how', u'well', u'does', u'this', u'work', u'podcasting'],\n",
       " [u'recording', u'phone', u'interview'],\n",
       " [u'zoom_h', u'display', u'failure'],\n",
       " [u'h', u'price', u'cuts'],\n",
       " [u'can', u'this', u'be_mounted', u'wall'],\n",
       " [u'i',\n",
       "  u'was_wondering',\n",
       "  u'if',\n",
       "  u'this',\n",
       "  u'microphone',\n",
       "  u'would',\n",
       "  u'work',\n",
       "  u'with',\n",
       "  u'cannon',\n",
       "  u'hd',\n",
       "  u'vixia_hf',\n",
       "  u'r',\n",
       "  u'video',\n",
       "  u'camera'],\n",
       " [u'is', u'this', u'an', u'xlr', u'plug'],\n",
       " [u'what', u'is', u'low'],\n",
       " [u'has_anyone',\n",
       "  u'cut',\n",
       "  u'these',\n",
       "  u'open',\n",
       "  u'looked_at',\n",
       "  u'shielding',\n",
       "  u'build_quality']]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qbigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QmodelB = models.Word2Vec(Qbigrams, size=100, window=5, min_count=10, workers=4)\n",
    "#AmodelB.most_similar(positive=['finna', 'gonna'], negative=['bro'],topn=20)\n",
    "#QmodelB.most_similar('hey') #positive=['finna', 'gonna'], negative=['bro'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'didn'' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-b0f7e80f277c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQmodelB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"didn'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/attiladobi/anaconda2/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'didn'' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "QmodelB.most_similar(\"didn'\",topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#QmodelB['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup logistic regression learning. User first word of sentence to identify type</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> get \"labeled\" data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'yes/no';\")\n",
    "Q_yn=cur.fetchall()\n",
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'open-ended';\")\n",
    "Q_oe=cur.fetchall()\n",
    "\n",
    "#only evaluate first sentence\n",
    "qs_yn= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_yn]\n",
    "qs_yn_sample=qs_yn[:int(len(qs_yn)/2)]\n",
    "\n",
    "qs_oe= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_oe]\n",
    "qs_oe_sample=qs_oe[:int(len(qs_oe)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_yn_sample[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qs_yn_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3213dc4bfb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqs_yn_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qs_yn_sample' is not defined"
     ]
    }
   ],
   "source": [
    "qs_yn_sample[i-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> setup vars </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_yn_arrays = np.zeros((len(qs_yn_sample), 100))\n",
    "all_oe_arrays = np.zeros((len(qs_oe_sample), 100))\n",
    "all_yn_labels = np.zeros(len(qs_yn_sample))\n",
    "all_oe_labels = np.zeros(len(qs_oe_sample))\n",
    "\n",
    "           \n",
    "#setup training for Y/N questions ... only tranin on the first word!\n",
    "for i in range(len(qs_yn_sample)):\n",
    "    if(qs_yn_sample[i]==[]):\n",
    "        qs_yn_sample[i]=['']\n",
    "    try:\n",
    "        all_yn_arrays[i] = QmodelB[qs_yn_sample[i][0]]\n",
    "    except KeyError:\n",
    "        all_yn_arrays[i] = all_yn_arrays[i-1]\n",
    "    all_yn_labels[i] = 1\n",
    "\n",
    "#setup training for open-ended questions\n",
    "for ii in range(len(qs_oe_sample)):\n",
    "    if(qs_oe_sample[ii]==[]):\n",
    "        qs_oe_sample[ii]=['']\n",
    "    try:\n",
    "        all_oe_arrays[ii] = QmodelB[qs_oe_sample[ii][0]]\n",
    "    except KeyError:\n",
    "        all_oe_arrays[ii]=all_oe_arrays[ii-1]\n",
    "    all_oe_labels[ii] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nyn=len(all_yn_arrays)\n",
    "Noe=len(all_oe_arrays)\n",
    "\n",
    "train_arrays = np.vstack((all_yn_arrays[:Nyn/2],all_oe_arrays[:Noe/2]))\n",
    "train_labels = np.hstack((all_yn_labels[:Nyn/2],all_oe_labels[:Noe/2]))\n",
    "\n",
    "test_arrays = np.vstack((all_yn_arrays[Nyn/2:],all_oe_arrays[Noe/2:]))\n",
    "test_labels = np.hstack((all_yn_labels[Nyn/2:],all_oe_labels[Noe/2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8011458130225837"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> test on real questions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "prediction=[]\n",
    "for line_arr in qs_yn[-1000:]:\n",
    "    try:\n",
    "        prediction.append(classifier.predict(QmodelB[line_arr[0]]))\n",
    "    except KeyError:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.837])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction)/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(QmodelB['can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for line_arr in qs_oe[-1000:]:\n",
    "    try:\n",
    "        prediction.append(classifier.predict(QmodelB[line_arr[0]]))\n",
    "    except KeyError:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.746])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([item ==0 for item in prediction])/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words_yn='is,will,wil,may,might,does,dose,doe,dos,do,can,could,must,shuold,are,would,do,did'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'will',\n",
       " ' wil',\n",
       " 'may',\n",
       " ' might',\n",
       " ' does',\n",
       " ' dose',\n",
       " ' doe',\n",
       " ' dos',\n",
       " ' do',\n",
       " ' can',\n",
       " ' could',\n",
       " ' must',\n",
       " ' shuold',\n",
       " ' are',\n",
       " ' would',\n",
       " ' do',\n",
       " ' did']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'could is a senctence'.split()[0] in bag_of_words_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> For cluter plot </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## emoji visual data ##########################################\n",
    "def clean_result(model_result):\n",
    "    return [item[0] for item in QmodelB.most_similar('you')],[item[1] for item in QmodelB.most_similar('you')]\n",
    "\n",
    "def visual(word):\n",
    "    word=word.lower()\n",
    "    results,counts=clean_result(QmodelB.most_similar(word))\n",
    "    source_target=[]\n",
    "    for result_word in results:\n",
    "        #append source target, and search next layer\n",
    "        source_target.append((word,result_word))\n",
    "        results2,counts2=clean_result(QmodelB.most_similar(result_word))\n",
    "        for result_word2 in results2:\n",
    "            source_target.append((result_word,result_word2))\n",
    "    return [{\"source\":src,\"target\":tar,\"type\":\"blah\"} for src,tar in source_target]\n",
    "\n",
    "def tree(word):\n",
    "    word=word.lower()\n",
    "    results,counts=clean_result(QmodelB.most_similar(word))\n",
    "    target=[]\n",
    "    child_list=[]\n",
    "    for result_word in results:\n",
    "        target_child=[]\n",
    "        target.append(result_word)\n",
    "        results2,counts2=clean_result(QmodelB.most_similar(result_word))\n",
    "        for result_word2 in results2:\n",
    "            target_child.append(result_word2)\n",
    "        child_list.append(target_child)\n",
    "    return target,child_list\n",
    "    #return [{\"source\":src,\"size\":tar} for src,tar in source_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word='you'\n",
    "target,child_list=tree(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': [{'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'u'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'we'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'i'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'yall'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'anyone'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'anybody'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'ability'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u\"y'all\"},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'your'},\n",
       "  {'children': [{'group': 3, 'name': u'u'},\n",
       "    {'group': 3, 'name': u'we'},\n",
       "    {'group': 3, 'name': u'i'},\n",
       "    {'group': 3, 'name': u'yall'},\n",
       "    {'group': 3, 'name': u'anyone'},\n",
       "    {'group': 3, 'name': u'anybody'},\n",
       "    {'group': 3, 'name': u'ability'},\n",
       "    {'group': 3, 'name': u\"y'all\"},\n",
       "    {'group': 3, 'name': u'your'},\n",
       "    {'group': 3, 'name': u'yourself'}],\n",
       "   'name': u'yourself'}],\n",
       " 'name': 'you'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"name\":word,\"children\":[{\"name\":tar,\"children\":[{\"name\":child,\"group\":3} for child in child_l] }\\\n",
    "                           for tar,child_l in zip(target,child_list)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> load and save </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QmodelB.save('QmodelB_update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QmodelB=models.Word2Vec.load('QmodelB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
